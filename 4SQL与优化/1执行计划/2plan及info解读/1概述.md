---
sidebar_position: 1
title: 概述
---
#

索引回表
-   大概1000万数据要30秒左右, 也要看cop_task的多少
-   为什么要说1000万? 说明是大表, region多, 数据也很散, rpc_num大

全表扫描或全索引扫描, 这个用时不好估, 有快有慢。

insert/update表中一行kv, 可能要附带处理表上几个索引的kv。   
从本章中截图的统计看:
-   修改数据的速度, 平均 大于1万个kv/秒 。  
-   commit的速度, 平均 6~10万kv/秒


## 场景一 select
单独的select, 或是DML中带的select

## 场景二 乐观insert values
-   如果有 auto_increment, 可能会多用几或几十毫秒
-   上锁时间省了, prewrite阶段上锁有一些时间, commit阶段应该快

理论上应该不慢, 如果索引不多, 插个200条(假设1000个kv), 可能一两百ms完成吧。  
如果速度不快, 可能tikv cpu高, 或region有热点。

## 场景三 乐观insert select
-   主要用时可能在select
-   上锁时间省了, prewrite阶段上锁有一些时间, commit阶段应该快

如果插个200条(假设1000个kv), 可能几百ms到1秒, 主要是看select。  
:::info
不少用户关心夜里跑批时, 批量插入的速度。主要还是看tikv繁忙程序, 以及region热点。
:::

## 场景四 乐观update join (select)
-   主要用时可能在select
-   上锁时间省了, prewrite阶段上锁有一些时间, commit阶段应该快
-   表中mvcc历史版本可能影响查询


## 场景五 悲观update join (select)
-   主要用时可能在select
-   上锁时间lock_rpc 可能较长
-   表中mvcc历史版本可能影响查询

## 场景六 DDL语句
加索引, 或是改表结构。


